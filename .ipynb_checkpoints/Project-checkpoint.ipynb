{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named urltools",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a7c9556a7d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minflect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0murltools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m##initialise dictionary containing all english words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named urltools"
     ]
    }
   ],
   "source": [
    "import webbrowser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import InvalidElementStateException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from time import sleep\n",
    "from itertools import permutations\n",
    "from xlrd import open_workbook\n",
    "import xlwt\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "import string\n",
    "import inflect\n",
    "import urltools\n",
    "\n",
    "##initialise dictionary containing all english words\n",
    "def initialise_dictionary():\n",
    "    \n",
    "    dictionary = []\n",
    "    \n",
    "    for line in open('words.txt','r'):\n",
    "        dictionary.append(line.rstrip())\n",
    "    \n",
    "    return dictionary\n",
    "\n",
    "#initialise dictionary containing all common words\n",
    "def initialise_common_words():\n",
    "    \n",
    "    common_words = []\n",
    "    \n",
    "    for line in open('common_words.txt'):\n",
    "        common_words.append(line.rstrip())\n",
    "        \n",
    "    return common_words\n",
    "\n",
    "#check if any word is in the dictionary\n",
    "def any_in_dictionary(list_of_words):\n",
    "    for word in list_of_words:\n",
    "        if word in d:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#write product dictionary to xls spreatsheet roughly following existing example\n",
    "def write_to_xls(websites, products, filename):\n",
    "    \n",
    "    print 'writing to xls file'\n",
    "\n",
    "    style1 = xlwt.easyxf('pattern: pattern solid, fore_colour red;')\n",
    "    style2 = xlwt.easyxf('pattern: pattern solid, fore_colour yellow;')\n",
    "    style3 = xlwt.easyxf('pattern: pattern solid, fore_colour green;')\n",
    "\n",
    "    book = xlwt.Workbook(encoding=\"utf-8\")\n",
    "\n",
    "    for product in products:\n",
    "\n",
    "        product_name = product['name']\n",
    "        product_model_number = product['model']\n",
    "        accessories = product['accessories']\n",
    "        \n",
    "        sh = book.add_sheet(product_name, cell_overwrite_ok=True)\n",
    "\n",
    "        col = 1\n",
    "        for website in websites:\n",
    "\n",
    "            website_name = website['name']\n",
    "            sh.write(0, col, website_name)\n",
    "            col += 1\n",
    "\n",
    "        sh.write(1, 0, product_name)\n",
    "\n",
    "        col = 1\n",
    "        for website in websites:\n",
    "\n",
    "            website_name = website['name']\n",
    "            if product[website_name] == 0:\n",
    "                s = style1\n",
    "            elif product[website_name] == 1:\n",
    "                s = style2\n",
    "            else:\n",
    "                s = style3\n",
    "            sh.write(1, col, '', s)\n",
    "            col += 1\n",
    "\n",
    "        row = 3\n",
    "        for accessory in accessories:\n",
    "\n",
    "            accessory_name = accessory['name']\n",
    "            sh.write(row, 0, accessory_name)\n",
    "            col = 1\n",
    "            for website in websites:\n",
    "                website_name = website['name']\n",
    "                if accessory[website_name] == 0:\n",
    "                    s = style1\n",
    "                elif accessory[website_name] == 1:\n",
    "                    s = style2\n",
    "                else:\n",
    "                    s = style3;\n",
    "                sh.write(row, col, '', s)\n",
    "                col += 1\n",
    "\n",
    "            row += 1\n",
    "\n",
    "    book.save(filename)\n",
    "    \n",
    "    print 'written xls file'\n",
    "\n",
    "#load xls file and extarct all product names\n",
    "def load_from_xls(filename):\n",
    "\n",
    "    wb = open_workbook(filename)\n",
    "\n",
    "    f = open('full_product_list.txt','w')\n",
    "\n",
    "    for s in wb.sheets()[1:]:\n",
    "\n",
    "        for r in range(s.nrows):\n",
    "\n",
    "            l = ''\n",
    "            skip = False\n",
    "            for c in reversed(range(2)):\n",
    "                v = s.cell(r, c).value\n",
    "                if v == '' or v == 'Model' or v == 'Part Number' or v == 'Option/Accessory'  \\\n",
    "                or v == 'Listed, accessory on product page, product or accesory needs optimising' \\\n",
    "                or v == 'Listed, accessory not on product page, needs optimising' or v == 'Not listed':\n",
    "                    skip = True\n",
    "                    break\n",
    "\n",
    "                l += '{} '.format(v)\n",
    "\n",
    "            if not skip:\n",
    "                f.write('{}\\n'.format(l))\n",
    "\n",
    "        f.write('\\n')\n",
    "\n",
    "#load list of products and webpages from txt files\n",
    "def load_from_txt_files(website_file, products_file):\n",
    "\n",
    "    #initilise list of websites\n",
    "    websites = []\n",
    "\n",
    "    #read text file line by line\n",
    "    for line in open(website_file,'r'):\n",
    "        #split by ' ', name, url, search keyword, search page, accessories, no result\n",
    "        strings = line.split()\n",
    "        \n",
    "        if strings[0] == '%': \n",
    "            continue\n",
    "\n",
    "        #add dictonary to list of websites\n",
    "        websites.append({'name' : strings[0], 'home_page' : strings[1], 'enable_javascript' : True})\n",
    "\n",
    "    #initialise list of products\n",
    "    products = []\n",
    "\n",
    "    #initialise current product\n",
    "    product = {}\n",
    "\n",
    "    #first line\n",
    "    first_line = True\n",
    "\n",
    "    #list of accessories\n",
    "    accessories = []\n",
    "\n",
    "    for line in open(products_file,'r'):\n",
    "\n",
    "        #empty line --end of accessories list\n",
    "        if line == '\\n':\n",
    "\n",
    "            if not product == {}:\n",
    "                product.update({'accessories' : accessories})\n",
    "                products.append(product)\n",
    "\n",
    "            product = {}\n",
    "            first_line = True\n",
    "            accessories = []\n",
    "\n",
    "            continue\n",
    "\n",
    "        #split line -- model number, name\n",
    "        strings = line.split()\n",
    "        model_number = strings[0]\n",
    "        name_parts = strings[1:]\n",
    "        for i in range(len(name_parts)):\n",
    "            if is_number(name_parts[i]):\n",
    "                name_parts[i] = inf_eng.number_to_words(name_parts[i])\n",
    "        product_name = ' '.join(name_parts).translate(None, string.punctuation).lower()\n",
    "\n",
    "        #dictionary for current product\n",
    "        p = {'model' : model_number, 'name' : product_name}\n",
    "\n",
    "        #add websites to p\n",
    "        for website in websites:\n",
    "\n",
    "            p.update({website['name'] : -1})\n",
    "\n",
    "        if first_line:\n",
    "\n",
    "            #set product\n",
    "            product = p\n",
    "            first_line = False\n",
    "\n",
    "        else:\n",
    "            #add to accessories list    \n",
    "            accessories.append(p)\n",
    "            \n",
    "    return websites, products\n",
    "\n",
    "#generate a list of candidate keywords from a model number ond product name\n",
    "def generate_keywords(model_number, name):\n",
    "    \n",
    "    #initilise keywords list\n",
    "    keywords = [model_number.lower(), name.lower()]\n",
    "    \n",
    "    #break name into list\n",
    "    l = name.split()\n",
    "    \n",
    "    if len(l) > 1:\n",
    "        for word in [w.translate(None, string.punctuation).lower() for w in l]:\n",
    "#             if word in d:\n",
    "#                 keywords.append(word)\n",
    "            if is_number(word):\n",
    "                word = inf_eng.number_to_words(word)\n",
    "            keywords.append(word)\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "#check if the current page is a search results page -- not great\n",
    "def is_results_page(url, search_term, website, start_search_url):\n",
    "    return any([word for word in search_term.split(' ') if word.upper() in url]) or '=' + search_term in url or \\\n",
    "        website['search_bar_name'] in url or url == start_search_url\n",
    "    \n",
    "#check current page is the correct product page\n",
    "def is_correct_product_page(browser, keywords, website, start_search_url):\n",
    "    \n",
    "    url = browser.current_url\n",
    "    print 'CHECKING PRODUCT PAGE... {}'.format(url)\n",
    "    \n",
    "    page_header = ''\n",
    "    try:\n",
    "        page_header = browser.find_element_by_tag_name('h1').text.lower()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    #firstly check if the page is a product page\n",
    "    if is_results_page(url, keywords[0], website, start_search_url) or \\\n",
    "    is_results_page(url, keywords[1], website, start_search_url):\n",
    "        \n",
    "        is_product_page = False\n",
    "        \n",
    "    elif keywords[0] in re.sub(r\"<a(.|(\\n))+</a>\", \"\", browser.page_source.lower()):\n",
    "             \n",
    "        is_product_page = True \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        is_product_page = False\n",
    "    \n",
    "    print 'it is the product: {}: {}'.format(keywords[1], is_product_page)  \n",
    "    \n",
    "    return is_product_page\n",
    "\n",
    "def new_browser(javascript_enabled, url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    prefs = {'profile.default_content_setting_values.notifications' : 2}\n",
    "    \n",
    "    if not javascript_enabled:\n",
    "         prefs.update({'profile.managed_default_content_settings.javascript' : 2})\n",
    "\n",
    "    chrome_options.add_experimental_option('prefs',prefs)\n",
    "\n",
    "    browser = webdriver.Chrome(chrome_options=chrome_options)\n",
    "    browser.maximize_window()\n",
    "    \n",
    "    global wait\n",
    "    wait = WebDriverWait(browser, wait_time)\n",
    "    \n",
    "    browser.get(url)\n",
    "    \n",
    "    browser = close_popup(browser)\n",
    "    \n",
    "    return browser\n",
    "\n",
    "#find the search bar of a webpage\n",
    "def find_search_bar(browser, website):\n",
    "    \n",
    "    url = browser.current_url\n",
    "    print 'looking for search bar on: {}'.format(url)\n",
    "\n",
    "    try:\n",
    "        search_bars = wait.until(EC.presence_of_all_elements_located((By.XPATH,\n",
    "                    '//input[@type=\\'search\\']|//input[@type=\\'text\\']')))\n",
    "    except TimeoutException:\n",
    "        print 'timeout while looking for search bars on {}, using a more general search'.format(url)\n",
    "#             search_bars = browser.find_elements_by_tag_name('input')\n",
    "        search_bars = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, 'input')))\n",
    "\n",
    "\n",
    "    print 'number of potential search bars found: {}'.format(len(search_bars))\n",
    "\n",
    "    name = ''\n",
    "\n",
    "    #iterate over all found search bars\n",
    "    for search_bar in search_bars:\n",
    "\n",
    "        try:\n",
    "            if search_bar.get_attribute('type') == 'hidden':\n",
    "                continue\n",
    "        except InvalidElementStateException:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            name = search_bar.get_attribute('name')\n",
    "\n",
    "            if name.lower() == 'username' or name.lower() == 'password':\n",
    "                continue\n",
    "\n",
    "            #clear search bar\n",
    "            search_bar.clear()\n",
    "\n",
    "            #search for model number\n",
    "            search_bar.send_keys(\"testing search bar\" + Keys.RETURN)\n",
    "\n",
    "            sleep(wait_time)\n",
    "            if browser.current_url != url:\n",
    "                return browser, name\n",
    "\n",
    "        except InvalidElementStateException:\n",
    "            #not a valid search bar\n",
    "            continue\n",
    "\n",
    "        except WebDriverException:\n",
    "            print 'cannot focus on search bar, closing popup on website: {}'.format(website['name'])\n",
    "            pass\n",
    "    \n",
    "    return browser, name\n",
    "\n",
    "#search a page for any links containing any of the keywords -- seems slow\n",
    "def search_for_links(browser, product_links, website):\n",
    "    \n",
    "    current_url = browser.current_url\n",
    "    \n",
    "    links = list(set(wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, 'a')))))\n",
    "    \n",
    "    for link in links:\n",
    "        \n",
    "        #get url\n",
    "        try:\n",
    "            url = link.get_attribute('href')\n",
    "            if not url or current_url == url or \\\n",
    "            '@' in url or 'pdf' in url or '#' in url:\n",
    "#             not any([word for word in website['name'].split('-') if word.lower() in url]):\n",
    "#             url in product_links or url in new_product_links:\n",
    "                continue\n",
    "        except StaleElementReferenceException:\n",
    "            continue\n",
    "          \n",
    "        #try to get text    \n",
    "        text = ''\n",
    "        try:\n",
    "            text = link.text\n",
    "        except StaleElementReferenceException:\n",
    "            pass\n",
    "        \n",
    "        tup = text.lower(), url\n",
    "#         if any([word for word in keywords if word in text.lower()]):\n",
    "#         and any([word for word in keywords if word.replace(' ','-') in url.lower() or word in title]):\n",
    "#             print u'accepted link with text: {}'.format(text)\n",
    "#             new_product_links.append(url)\n",
    "        if url not in [u for t,u in product_links]:\n",
    "            product_links.append(tup)\n",
    "    \n",
    "#     print 'number of potential links found: {}'.format(len(product_links))\n",
    "            \n",
    "    return product_links\n",
    "\n",
    "#go through list of links until product is found\n",
    "def follow_links(browser, keywords, product_links, website, start_search_url):\n",
    "    \n",
    "    #iterate over links\n",
    "    for link in product_links:\n",
    "        \n",
    "        text, url = link\n",
    "        \n",
    "        if any([word for word in keywords if word in text]) or\\\n",
    "        any([word for word in keywords if word.replace(' ','-') in url]):\n",
    "            print 'clicking on: {}'.format(url)\n",
    "            browser.get(url)\n",
    "        else: \n",
    "            continue\n",
    "        \n",
    "        #if the link is to a results page -- append found links to product links\n",
    "        if is_results_page(browser.current_url, keywords[0], website, start_search_url) or \\\n",
    "        is_results_page(browser.current_url, keywords[1], website, start_search_url):\n",
    "            continue\n",
    "        \n",
    "        #return immediately if the product is found\n",
    "        if is_correct_product_page(browser, keywords, website, start_search_url):\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "#find all links to the same page by looking for '#'\n",
    "def get_links_to_same_page(browser):\n",
    "    \n",
    "    product_url = browser.current_url\n",
    "    \n",
    "    links = list(set(wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, 'a')))))\n",
    "    \n",
    "    links_to_same_page = []\n",
    "\n",
    "    for link in links:\n",
    "        \n",
    "        try:\n",
    "            cl = link.get_attribute('class')\n",
    "            \n",
    "            if not not cl:\n",
    "            \n",
    "                if 'tab' in cl or 'anchor' in cl:\n",
    "                    links_to_same_page.append(link)\n",
    "                    continue\n",
    "            \n",
    "        except StaleElementReferenceException:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            url = link.get_attribute('href')\n",
    "            \n",
    "            if not url:\n",
    "                continue\n",
    "            \n",
    "            if re.match(product_url + '#\\S+', url):\n",
    "                links_to_same_page.append(link)\n",
    "                \n",
    "        except StaleElementReferenceException:\n",
    "            continue\n",
    "    \n",
    "    return links_to_same_page\n",
    "\n",
    "def close_popup(browser):\n",
    "    \n",
    "    try:\n",
    "        button = browser.find_element_by_xpath('//button[@class=\\'close\\']')\n",
    "        browser.execute_script(\"arguments[0].click();\", button)\n",
    "#         button.click()\n",
    "        print 'closed popup'\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    return browser\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if we have searched a website for an accessory and found it / did not find it, then we can mark\n",
    "#it found or not found for all products with the same accessory\n",
    "def mark_accessory_for_all_products(website_name, products, \n",
    "                                    accessory_model_number, found_accessory, accessory_url):\n",
    "    \n",
    "    print 'marking {} for all products'.format(accessory_model_number)\n",
    "    \n",
    "    for product in products:\n",
    "        \n",
    "        product_name = product['name']\n",
    "        accessories = product['accessories']\n",
    "        \n",
    "        for accessory in accessories:\n",
    "            \n",
    "            if accessory['model'].lower() == accessory_model_number and accessory[website_name] != 2:\n",
    "                \n",
    "                #store search result\n",
    "                if found_accessory:\n",
    "                    accessory[website_name] = 1\n",
    "                else:\n",
    "                    accessory[website_name] = 0\n",
    "                #save url of accessory\n",
    "                accessory['{}_url'.format(website_name)] = accessory_url\n",
    "                \n",
    "                print 'marked {} as found: {} for product {}'.format(accessory_model_number, \n",
    "                                                                     found_accessory, product_name)\n",
    "                break\n",
    "                \n",
    "def load_home_page(browser, website):\n",
    "    \n",
    "    browser.get(website['home_page'])\n",
    "    browser = close_popup(browser)\n",
    "    \n",
    "    return browser\n",
    "\n",
    "#main method that deals with searching an entire website for a product\n",
    "def search_website_for_product(browser, product, keywords, website):\n",
    "    \n",
    "    #search by model number then name\n",
    "    for word in keywords[:2]:\n",
    "        \n",
    "        try:\n",
    "            search_bars = wait.until(EC.presence_of_all_elements_located((By.XPATH,\n",
    "                    '//input[contains(@name,\\'{}\\')]'.format(website['search_bar_name']))))\n",
    "        except TimeoutException:\n",
    "            print 'could not find search bar called {}, reloading website home page'.format(website['search_bar_name'])\n",
    "            browser = load_home_page(browser, website)\n",
    "            search_bars = wait.until(EC.presence_of_all_elements_located((By.XPATH,\n",
    "                    '//input[contains(@name,\\'{}\\')]'.format(website['search_bar_name']))))\n",
    "        \n",
    "        print 'searching for \\'{}\\''.format(word)\n",
    "\n",
    "        try:\n",
    "            start_search_url = browser.current_url\n",
    "        except Exception:\n",
    "            sleep(1)\n",
    "            start_search_url = browser.current_url\n",
    "            \n",
    "        for search_bar in search_bars:\n",
    "\n",
    "            try:\n",
    "                #clear search bar\n",
    "                search_bar.clear()\n",
    "\n",
    "                #search for model number\n",
    "                search_bar.send_keys(word.upper() + Keys.RETURN)\n",
    "\n",
    "                sleep(wait_time)\n",
    "                if browser.current_url != start_search_url:\n",
    "                    break\n",
    "\n",
    "            except (InvalidElementStateException,\n",
    "                    StaleElementReferenceException,\n",
    "                    NoSuchElementException) as e:\n",
    "                continue\n",
    "\n",
    "        print 'successfully performed search'\n",
    "        \n",
    "        is_home_page = browser.current_url == website['home_page']\n",
    "\n",
    "        if not is_home_page and not is_results_page(browser.current_url, word, website, start_search_url):\n",
    "\n",
    "            found_product = is_correct_product_page(browser, keywords, website, start_search_url)\n",
    "\n",
    "            print 'have been directed to a product immediately, it is the correct product: {}'.format(found_product)\n",
    "\n",
    "        else:\n",
    "\n",
    "            print 'directed to search results page {}, now searching for links to product'.format(browser.current_url)\n",
    "\n",
    "            #search for potential links to product\n",
    "            product_links = search_for_links(browser, [], website)\n",
    "\n",
    "            #click on links until product is found\n",
    "            found_product = follow_links(browser, keywords, product_links, website, start_search_url)\n",
    "\n",
    "        if found_product: \n",
    "            \n",
    "            return browser, True, browser.current_url\n",
    "        else:\n",
    "            print 'did not find product with search term: \\'{}\\''.format(word)\n",
    "            print\n",
    "    \n",
    "    return browser, False, None\n",
    "\n",
    "#save object to pkl\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#load object from pkl\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def search_bar(browser, websites, website, website_save):\n",
    "    if 'search_bar_name' not in website:\n",
    "        #find search bar\n",
    "        browser, website['search_bar_name'] = find_search_bar(browser, website)\n",
    "\n",
    "        print 'found search bar name for {}: \\'{}\\''.format(website['name'], website['search_bar_name'])\n",
    "\n",
    "        save_obj(websites, website_save)\n",
    "        print 'saving search bar name'\n",
    "    else:\n",
    "        print 'already know the name of the search bar on {}, it is {}'.format(website['name'], website['search_bar_name'])\n",
    "    \n",
    "    return browser\n",
    "    \n",
    "def product_search(browser, website, products, product_save):\n",
    "    \n",
    "    website_name = website['name']\n",
    "        \n",
    "    #iterate over all products\n",
    "    for product in products:\n",
    "\n",
    "        #get information about produst\n",
    "        model_number = product['model'].lower()\n",
    "        product_name = product['name'].lower()\n",
    "\n",
    "        ##check where we left off\n",
    "        if product[website_name] != -1:\n",
    "            print 'already searched for {} on {}, moving to next product'.format(product_name, website_name)\n",
    "            continue\n",
    "\n",
    "        print_divider('PRODUCT NAME: {}, MODEL NUMBER: {}'.format(product_name, model_number), 1)\n",
    "\n",
    "        #generate list of keywords to search for\n",
    "        product_keywords = generate_keywords(model_number, product_name)\n",
    "\n",
    "        print 'PRODUCT KEYWORDS'\n",
    "        print product_keywords\n",
    "\n",
    "        #search entire website for product\n",
    "        browser, found_product, product_url = search_website_for_product(browser, product, product_keywords, website)\n",
    "\n",
    "        #save result for that website\n",
    "        if found_product:\n",
    "            product[website_name] = 2\n",
    "        else:\n",
    "            product[website_name] = 0\n",
    "        \n",
    "        #save url of product\n",
    "        product['{}_url'.format(website_name)] = product_url\n",
    "\n",
    "        print 'found {} on {}: {}'.format(product_name, website_name, found_product)\n",
    "        \n",
    "        print 'saving dictionary so far'\n",
    "        print\n",
    "        save_obj(products, product_save)\n",
    "    \n",
    "    return browser\n",
    "                \n",
    "def accessory_search(browser, website, products, product_save):\n",
    "    \n",
    "    website_name = website['name']\n",
    "     \n",
    "    #now search website for accessories\n",
    "    for product in products:\n",
    "\n",
    "        #list of accessories\n",
    "        accessories = product['accessories']\n",
    "\n",
    "        #if we have not already found the accessory -- search for accessory using search bar\n",
    "        for accessory in accessories:\n",
    "\n",
    "            #get model number and name of accessory\n",
    "            accessory_model_number = accessory['model'].lower()\n",
    "            accessory_name = accessory['name'].lower()\n",
    "            \n",
    "            if accessory[website_name] != -1:\n",
    "                print 'already searched for {} on {}, moving to next accessory'.format(accessory_name, website_name)\n",
    "                continue\n",
    "\n",
    "            print_divider('ACCESSORY NAME: {}, MODEL NUMBER: {}'.format(accessory_name, accessory_model_number), 1)\n",
    "\n",
    "            #generate search keywords\n",
    "            accessory_keywords = generate_keywords(accessory_model_number, accessory_name)\n",
    "\n",
    "            print 'ACCESSORY KEYWORDS'\n",
    "            print accessory_keywords\n",
    "\n",
    "            #search website for model number and accessory name\n",
    "            browser, found_accessory, accessory_url = search_website_for_product(browser, accessory, accessory_keywords, website)\n",
    "            \n",
    "            print 'found {} on {}: {}'.format(accessory_name, website_name, found_accessory)\n",
    "            \n",
    "            #mark accessory found/not found for every product\n",
    "            mark_accessory_for_all_products(website_name, products, accessory_model_number, found_accessory, accessory_url)\n",
    "            \n",
    "            print 'saving dictionary so far'\n",
    "#             save_obj(products, product_save)\n",
    "            \n",
    "    return browser\n",
    "\n",
    "# def search_page_for_url(links, url):\n",
    "\n",
    "# #     try:\n",
    "# # #         link = browser.find_element_by_xpath('//a[contains(translate(@href,\\'-\\',\\'\\'),\\'{}\\')]'.format(url.replace('-','')))\n",
    "# #         link = wait.until(EC.presence_of_all_elements_located((By.XPATH, '//a[contains(translate(@href,\\'-\\',\\'\\'),\\'{}\\')]'.format(url.replace('-','')))))\n",
    "# #         print 'successful'\n",
    "# #     except (NoSuchElementException, TimeoutException) as e:\n",
    "# #         print 'was not successful'\n",
    "# #         return False\n",
    "\n",
    "#     path = getattr(urltools.parse(url),'path')\n",
    "    \n",
    "#     print 'searching for link containing {}'.format(path)\n",
    "    \n",
    "#     for link in links:\n",
    "#         check_path = getattr(urltools.parse(link),'path')\n",
    "# #         print check_path\n",
    "#         if check_path == path:\n",
    "#             print 'successful'\n",
    "#             return True\n",
    "    \n",
    "#     print 'unsuccessful'\n",
    "#     return False\n",
    "\n",
    "def accessories_on_product_page(browser, website, products, websites, product_save, website_save):\n",
    "    \n",
    "    print 'performing scan of all product pages for accessories'\n",
    "    \n",
    "    website_name = website['name'] \n",
    "    \n",
    "    for product in products:\n",
    "        \n",
    "        if product[website_name] == 0:\n",
    "            print\n",
    "            print 'did not find product: {} on {}, continuing to next product'.format(product['name'], website_name)\n",
    "            print\n",
    "            continue\n",
    "        \n",
    "        #product url\n",
    "        product_name = product['name']\n",
    "        product_url = product['{}_url'.format(website_name)]\n",
    "        \n",
    "        print_divider(product_name, 1)\n",
    "\n",
    "        browser.get(product_url)\n",
    "\n",
    "        links = search_for_links(browser, [], website)\n",
    "        \n",
    "        anchor_links = get_links_to_same_page(browser)\n",
    "        \n",
    "        print\n",
    "        print 'ANCHOR LINKS: {}'.format(len(anchor_links))\n",
    "        for anchor_link in anchor_links:\n",
    "            print anchor_link.get_attribute('href')\n",
    "        print \n",
    "        \n",
    "        for anchor_link in anchor_links:\n",
    "            browser.execute_script(\"arguments[0].click();\", anchor_link)\n",
    "            links = search_for_links(browser, links, website)\n",
    "        \n",
    "        #list of accessories\n",
    "        accessories = product['accessories']\n",
    "        #iterate over all accessories\n",
    "        for accessory in accessories:\n",
    "            \n",
    "            #accessory attribute\n",
    "            accessory_name = accessory['name']\n",
    "            accessory_model_number = accessory['model']\n",
    "            \n",
    "            #if we did not find accessory or accessory has been completed, continue\n",
    "            if accessory[website_name] == 2:\n",
    "                print 'accessory {} was already found on {}'.format(accessory_name, website_name)\n",
    "                continue\n",
    "#             if '{}_done'.format(website_name) in accessory:\n",
    "#                 print 'accessory {} is done on {}'.format(accessory_name, website_name)\n",
    "#                 continue\n",
    "\n",
    "\n",
    "\n",
    "            accessory_keywords = generate_keywords(accessory_model_number, accessory_name)\n",
    "            \n",
    "            print_divider(accessory_name, 1)\n",
    "                \n",
    "            print 'ACCESSORY KEYWORDS'\n",
    "            print accessory_keywords\n",
    "            \n",
    "#             accessory_links = search_for_links(browser, accessory_keywords, [browser.current_url], website)\n",
    "            \n",
    "            if follow_links(browser, accessory_keywords, links, website, browser.current_url):\n",
    "                print 'found {} on page of product: {}'.format(accessory_name, product_name)\n",
    "                accessory[website_name] = 2\n",
    "            \n",
    "            print 'product page searched for accessory {}, saving progress'.format(accessory_name)\n",
    "            save_obj(products, product_save)\n",
    "    return browser\n",
    "            \n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "            \n",
    "def print_divider(string, n):\n",
    "    string = ' ' + string + ' '\n",
    "    l = 80\n",
    "    print\n",
    "    for i in range(n):\n",
    "        print '*' * l\n",
    "    print '-' * ((l - len(string)) / 2) + string.upper() + '-' * ((l - len(string)) / 2)\n",
    "    for i in range(n):\n",
    "        print '*' * l\n",
    "    print\n",
    "\n",
    "#main searchi function\n",
    "def search(website_file, product_file, product_save, website_save):\n",
    "    \n",
    "    print_divider('beginning search', 2)\n",
    "    print_divider('initialisation', 2)\n",
    "    \n",
    "    ##load data from txt files\n",
    "    websites, products = load_from_txt_files(website_file, product_file)\n",
    "    \n",
    "    print 'number of products: {}'.format(len(products))\n",
    "\n",
    "    ##load in-progress products\n",
    "    if os.path.isfile(product_save + '.pkl'):\n",
    "        print 'search already in progress, continuing where I left off'\n",
    "        print 'loaded products'\n",
    "        products = load_obj(product_save)\n",
    "    else:\n",
    "        print 'no saved products file, creating one'\n",
    "        \n",
    "    if os.path.isfile(website_save + '.pkl'):\n",
    "        print 'loaded websites'\n",
    "        websites = load_obj(website_save)\n",
    "    else:\n",
    "        print 'no saved websites file, creating one'\n",
    "\n",
    "    #chrome preferences\n",
    "#     chrome_options = webdriver.ChromeOptions()\n",
    "#     prefs = {'profile.default_content_setting_values.notifications' : 2, \n",
    "#              'profile.managed_default_content_settings.javascript' : 2}\n",
    "# #     prefs = {'profile.default_content_setting_values.notifications' : 2,\n",
    "# #             'profile.default_content_settings.popups': 2}\n",
    "#     chrome_options.add_experimental_option('prefs',prefs)\n",
    "\n",
    "    \n",
    "#     #firefox preferences\n",
    "#     fp = webdriver.FirefoxProfile()\n",
    "#     fp.set_preference(\"privacy.popups.disable_from_plugins\", 3)\n",
    "#     fp.set_preference(\"dom.push.enabled\", False)\n",
    "#     fp.set_preference(\"dom.webnotifications.enabled\", False)\n",
    "    \n",
    "#     #iniaialise forefox browser\n",
    "#     browser = webdriver.Firefox(fp)\n",
    "\n",
    "    #sleep time\n",
    "    global wait_time\n",
    "    wait_time = 5\n",
    "\n",
    "    #maximum number of retires to wait for an element\n",
    "    global retries \n",
    "    retries = 3\n",
    "    \n",
    "    global inf_eng\n",
    "    inf_eng = inflect.engine()\n",
    "    \n",
    "    try:\n",
    "\n",
    "        #iterate over all websites\n",
    "        for website in websites:\n",
    "\n",
    "            #get information about website\n",
    "            website_name = website['name']\n",
    "            website_url = website['home_page']\n",
    "\n",
    "            if 'done' in website:\n",
    "                print '{} has been fully completed, moving to next website'.format(website_name)\n",
    "                continue\n",
    "\n",
    "            print_divider('WEBSITE: {}'.format(website_name), 2) \n",
    "\n",
    "            #initialise Chrome browser\n",
    "            browser = new_browser(website['enable_javascript'], website_url)\n",
    "\n",
    "            #explicit wait\n",
    "            wait = WebDriverWait(browser, wait_time)\n",
    "\n",
    "            print_divider('locate search bar', 2)\n",
    "\n",
    "            #find search bar for website\n",
    "            browser = search_bar(browser, websites, website, website_save)\n",
    "\n",
    "            print_divider('product search', 2)\n",
    "\n",
    "            #search this website for all products\n",
    "            browser = product_search(browser, website, products, product_save)\n",
    "            \n",
    "            print_divider('check accessories are listed on product page', 2)\n",
    "\n",
    "            #check product page for accessory links\n",
    "            browser = accessories_on_product_page(browser, website, products, websites, product_save, website_save)\n",
    "\n",
    "            print_divider('accessory search', 2)\n",
    "\n",
    "            #search this website for all accessories\n",
    "            browser = accessory_search(browser, website, products, product_save)\n",
    "\n",
    "            #record that we have completed this website\n",
    "            website['done'] = True\n",
    "            print\n",
    "            print 'marked {} as done'.format(website_name)\n",
    "\n",
    "            save_obj(websites, website_save)\n",
    "            print 'saved websites'\n",
    "            print \n",
    "\n",
    "            #close browser for this website\n",
    "            browser.quit()\n",
    "\n",
    "\n",
    "        print_divider('SEARCH COMPLETE', 2)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        browser.quit()\n",
    "    \n",
    "    return websites, products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "------------------------------- BEGINNING SEARCH -------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "-------------------------------- INITIALISATION --------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "number of products: 6\n",
      "search already in progress, continuing where I left off\n",
      "loaded products\n",
      "loaded websites\n",
      "Inmac-wstore has been fully completed, moving to next website\n",
      "Misco has been fully completed, moving to next website\n",
      "Insight has been fully completed, moving to next website\n",
      "Pixmania has been fully completed, moving to next website\n",
      "\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "-------------------------------- WEBSITE: LDLC --------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "------------------------------ LOCATE SEARCH BAR ------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "already know the name of the search bar on LDLC, it is ctl00$ucHeaderControl$txtSearch\n",
      "\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "-------------------------------- PRODUCT SEARCH --------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "already searched for s1100i on LDLC, moving to next product\n",
      "already searched for ix100 on LDLC, moving to next product\n",
      "already searched for s1300i on LDLC, moving to next product\n",
      "already searched for s1300i deluxe on LDLC, moving to next product\n",
      "already searched for ix500 on LDLC, moving to next product\n",
      "already searched for ix500 deluxe on LDLC, moving to next product\n",
      "\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "----------------- CHECK ACCESSORIES ARE LISTED ON PRODUCT PAGE -----------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "performing scan of all product pages for accessories\n",
      "\n",
      "********************************************************************************\n",
      "------------------------------------ S1100I ------------------------------------\n",
      "********************************************************************************\n",
      "\n",
      "number of potential links found: 445\n",
      "\n",
      "ANCHOR LINKS: 0\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "-------------------------------- SCANSNAP CASE --------------------------------\n",
      "********************************************************************************\n",
      "\n",
      "ACCESSORY KEYWORDS\n",
      "['pa03610-0001', 'scansnap case', 'scansnap', 'case']\n",
      "clicking on: http://www.ldlc.com/fiche/PB00212578.html\n",
      "CHECKING PRODUCT PAGE... http://www.ldlc.com/fiche/PB00212578.html\n",
      "it is the product: scansnap case: False\n",
      "clicking on: http://www.ldlc.com/fiche/PB00176695.html\n",
      "CHECKING PRODUCT PAGE... http://www.ldlc.com/fiche/PB00176695.html\n",
      "it is the product: scansnap case: False\n",
      "clicking on: javascript:WebForm_DoPostBackWithOptions(new WebForm_PostBackOptions(\"ctl00$cphMainContent$lbAddComment\", \"\", false, \"\", \"https://secure.ldlc.com/Account/LoginPage.aspx?redir=http%3a%2f%2fwww.ldlc.com%2fcomment%2fadd%2fc4283%2fp201507080105%2ffujitsu-scansnap-s1100i%2f\", false, true))\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: unsupported protocol\n  (Session info: chrome=56.0.2924.87)\n  (Driver info: chromedriver=2.26.436362 (5476ec6bf7ccbada1734a0cdec7d570bb042aa30),platform=Windows NT 10.0.14393 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-17257c609eef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[1;34m'products_new_line.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[1;34m'saved_products_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                             'saved_websites_{}'.format(country))\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ca951192ed43>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(website_file, product_file, product_save, website_save)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[1;31m#check product page for accessory links\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccessories_on_product_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwebsite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproducts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwebsites\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproduct_save\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwebsite_save\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mprint_divider\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accessory search'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ca951192ed43>\u001b[0m in \u001b[0;36maccessories_on_product_page\u001b[0;34m(browser, website, products, websites, product_save, website_save)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[1;31m#             accessory_links = search_for_links(browser, accessory_keywords, [browser.current_url], website)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mif\u001b[0m \u001b[0mfollow_links\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccessory_keywords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwebsite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m'found {} on page of product: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccessory_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproduct_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0maccessory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwebsite_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ca951192ed43>\u001b[0m in \u001b[0;36mfollow_links\u001b[0;34m(browser, keywords, product_links, website, start_search_url)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m        \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m'clicking on: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Miniconda3\\envs\\py27\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Miniconda3\\envs\\py27\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    238\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32mC:\\Miniconda3\\envs\\py27\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.pyc\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mexception_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mUnexpectedAlertPresentException\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'alert'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: unsupported protocol\n  (Session info: chrome=56.0.2924.87)\n  (Driver info: chromedriver=2.26.436362 (5476ec6bf7ccbada1734a0cdec7d570bb042aa30),platform=Windows NT 10.0.14393 x86_64)\n"
     ]
    }
   ],
   "source": [
    "country = 'fr'\n",
    "\n",
    "websites, products = search('webpages_{}.txt'.format(country),\n",
    "                            'products_new_line.txt',\n",
    "                            'saved_products_{}'.format(country),\n",
    "                            'saved_websites_{}'.format(country))\n",
    "\n",
    "print\n",
    "\n",
    "write_to_xls(websites, products, 'output_{}.xls'.format(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = OptionParser()\n",
    "    parser.add_option(\"-w\", \"--webpages\", dest=\"webpages_file\",\n",
    "                      help=\"txt file containing website names and URLs, defaults to webpages.txt\", default='webpages.txt')\n",
    "    parser.add_option(\"-p\", \"--products\", dest=\"products_file\",\n",
    "                      help=\"xls file contianing all products and accessories on separate tabs -- REQUIRED\")\n",
    "    parser.add_option(\"-o\", \"--output\", dest=\"output_file\",\n",
    "                      help=\"xls file to output to, .xls is required. defaults to output.xls\",default='output.xls')\n",
    "    parser.add_option(\"-s\", \"--save\", dest=\"save_file\",\n",
    "                      help=\"filename to load/save products search\",default='saved_products')\n",
    "    \n",
    "    (options, args) = parser.parse_args()\n",
    "    \n",
    "    ##load product list from xls into txt\n",
    "    load_from_xls(options.products_file)\n",
    "    \n",
    "    ##run/resume search \n",
    "    search(options.save_file)\n",
    "    \n",
    "    print 'SEARCH COMPLETE'\n",
    "    \n",
    "    ##write to xls\n",
    "    write_to_xls(options.output_file)\n",
    "    \n",
    "    print 'written to output file ' + options.output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_to_xls(websites, products, 'output_be.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: Failed to decode response from marionette\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-c6caa00e38a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFirefox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.pixmania.fr/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Miniconda3\\envs\\py27\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Miniconda3\\envs\\py27\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    238\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32mC:\\Miniconda3\\envs\\py27\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.pyc\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mexception_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mUnexpectedAlertPresentException\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'alert'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: Failed to decode response from marionette\n"
     ]
    }
   ],
   "source": [
    "# fp = webdriver.FirefoxProfile()\n",
    "# fp.set_preference(\"privacy.popups.disable_from_plugins\", 3)\n",
    "# fp.set_preference(\"dom.push.enabled\", False)\n",
    "# fp.set_preference(\"dom.webnotifications.enabled\", False)\n",
    "\n",
    "# browser = webdriver.Firefox(fp)\n",
    "\n",
    "browser.get('https://www.pixmania.fr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: __main__.py [options]\n",
      "\n",
      "__main__.py: error: no such option: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\py27\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
